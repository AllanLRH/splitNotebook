{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script rips zalando for sweaters and sorts the results based in wool content in the sweaters"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This cell contains raw nbconvert text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import urllib2\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPageSoup(pg):\n",
    "    baseUrl = 'https://www.zalando.dk/herretoej-sweatere-og-strikjakker/?price_to=500&upper_material=kashmir.mohair.uld&order=price&dir=asc'\n",
    "    # html = urllib2.urlopen(baseUrl % pg).read()\n",
    "    html = urllib2.urlopen(baseUrl).read()\n",
    "    return BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "soup = getPageSoup(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(urllib2.urlopen('https://www.zalando.dk/herretoej-sweatere-og-strikjakker/?upper_material=uld&shirt_collar=sjalskrave&order=price&dir=asc').read(), 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPageProducts(soup):\n",
    "    searchBox = soup.find('ul', class_='catalogArticlesList  threeCol main')\n",
    "    productList = searchBox.findAll('a', class_='catalogArticlesList_productBox')\n",
    "    productLinks = ['https://www.zalando.dk' + a.attrs['href'] for a in productList]\n",
    "    return productLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "productLinks = getPageProducts(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getProductSoup(url):\n",
    "    html = urllib2.urlopen(url).read()\n",
    "    return BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getWollContent(soup):\n",
    "    productInfo = soup.find('div', attrs={'id': 'productDetails', 'class': 'span6'})\n",
    "    ul = productInfo.find('ul')\n",
    "    rx = re.compile(r'.*?(\\d+)\\s*\\% uld.*?')\n",
    "    for ln in ul.text.splitlines():\n",
    "        m = rx.match(ln)\n",
    "        if m:\n",
    "            return int(m.groups()[0].strip())\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aggregateList = list()\n",
    "for pg in range(1,6):\n",
    "    pageSoup = getPageSoup(pg)\n",
    "    productLinks = getPageProducts(pageSoup)\n",
    "    for pd in productLinks:\n",
    "        try:\n",
    "            prodSoup = getProductSoup(pd)\n",
    "            woolCont = getWollContent(prodSoup)\n",
    "            aggregateList.append((woolCont, pd))\n",
    "        except AttributeError as e:\n",
    "            print('Failed at URL %s ' % pd)\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(aggregateList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "mpl.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "pct = [el[0] for el in aggregateList]\n",
    "plt.hist(pct, 100);\n",
    "plt.xticks(range(0, 101, 5));\n",
    "plt.xlabel('% wool');\n",
    "plt.ylabel('# products');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('woolen_sweaters_urls.txt', 'w') as fid:\n",
    "    map(lambda x: print(x[1], file=fid), sorted([el for el in aggregateList if el[0] > 50], key=lambda x: x[0], reverse=True));\n",
    "map(lambda x: print(x[1]), sorted([el for el in aggregateList if el[0] > 50], key=lambda x: x[0], reverse=True));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "map(lambda x:print(x[1]), [el for el in aggregateList if el[0] == 50]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import webbrowser\n",
    "# map(lambda x: webbrowser.open_new_tab(x[1]), [el for el in aggregateList if el[0] > 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
